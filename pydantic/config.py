"""Configuration for Pydantic models."""
from __future__ import annotations as _annotations
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Type, TypeVar, Union
from typing_extensions import Literal, TypeAlias, TypedDict
from ._migration import getattr_migration
from .aliases import AliasGenerator
from .errors import PydanticUserError
if TYPE_CHECKING:
    from ._internal._generate_schema import GenerateSchema as _GenerateSchema
    from .fields import ComputedFieldInfo, FieldInfo
__all__ = ('ConfigDict', 'with_config')
JsonValue: TypeAlias = Union[int, float, str, bool, None, List['JsonValue'], 'JsonDict']
JsonDict: TypeAlias = Dict[str, JsonValue]
JsonEncoder = Callable[[Any], Any]
JsonSchemaExtraCallable: TypeAlias = Union[Callable[[JsonDict], None], Callable[[JsonDict, Type[Any]], None]]
ExtraValues = Literal['allow', 'ignore', 'forbid']

class ConfigDict(TypedDict, total=False):
    """A TypedDict for configuring Pydantic behaviour."""

    def __init__(self, **kwargs: Any) -> None:
        super().__init__(**kwargs)
    title: str | None
    "The title for the generated JSON schema, defaults to the model's name"
    model_title_generator: Callable[[type], str] | None
    'A callable that takes a model class and returns the title for it. Defaults to `None`.'
    field_title_generator: Callable[[str, FieldInfo | ComputedFieldInfo], str] | None
    "A callable that takes a field's name and info and returns title for it. Defaults to `None`."
    str_to_lower: bool
    'Whether to convert all characters to lowercase for str types. Defaults to `False`.'
    str_to_upper: bool
    'Whether to convert all characters to uppercase for str types. Defaults to `False`.'
    str_strip_whitespace: bool
    'Whether to strip leading and trailing whitespace for str types.'
    str_min_length: int
    'The minimum length for str types. Defaults to `None`.'
    str_max_length: int | None
    'The maximum length for str types. Defaults to `None`.'
    extra: ExtraValues | None
    "\n    Whether to ignore, allow, or forbid extra attributes during model initialization. Defaults to `'ignore'`.\n\n    You can configure how pydantic handles the attributes that are not defined in the model:\n\n    * `allow` - Allow any extra attributes.\n    * `forbid` - Forbid any extra attributes.\n    * `ignore` - Ignore any extra attributes.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict\n\n\n    class User(BaseModel):\n        model_config = ConfigDict(extra='ignore')  # (1)!\n\n        name: str\n\n\n    user = User(name='John Doe', age=20)  # (2)!\n    print(user)\n    #> name='John Doe'\n    ```\n\n    1. This is the default behaviour.\n    2. The `age` argument is ignored.\n\n    Instead, with `extra='allow'`, the `age` argument is included:\n\n    ```py\n    from pydantic import BaseModel, ConfigDict\n\n\n    class User(BaseModel):\n        model_config = ConfigDict(extra='allow')\n\n        name: str\n\n\n    user = User(name='John Doe', age=20)  # (1)!\n    print(user)\n    #> name='John Doe' age=20\n    ```\n\n    1. The `age` argument is included.\n\n    With `extra='forbid'`, an error is raised:\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, ValidationError\n\n\n    class User(BaseModel):\n        model_config = ConfigDict(extra='forbid')\n\n        name: str\n\n\n    try:\n        User(name='John Doe', age=20)\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for User\n        age\n        Extra inputs are not permitted [type=extra_forbidden, input_value=20, input_type=int]\n        '''\n    ```\n    "
    frozen: bool
    '\n    Whether models are faux-immutable, i.e. whether `__setattr__` is allowed, and also generates\n    a `__hash__()` method for the model. This makes instances of the model potentially hashable if all the\n    attributes are hashable. Defaults to `False`.\n\n    Note:\n        On V1, the inverse of this setting was called `allow_mutation`, and was `True` by default.\n    '
    populate_by_name: bool
    "\n    Whether an aliased field may be populated by its name as given by the model\n    attribute, as well as the alias. Defaults to `False`.\n\n    Note:\n        The name of this configuration setting was changed in **v2.0** from\n        `allow_population_by_field_name` to `populate_by_name`.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, Field\n\n\n    class User(BaseModel):\n        model_config = ConfigDict(populate_by_name=True)\n\n        name: str = Field(alias='full_name')  # (1)!\n        age: int\n\n\n    user = User(full_name='John Doe', age=20)  # (2)!\n    print(user)\n    #> name='John Doe' age=20\n    user = User(name='John Doe', age=20)  # (3)!\n    print(user)\n    #> name='John Doe' age=20\n    ```\n\n    1. The field `'name'` has an alias `'full_name'`.\n    2. The model is populated by the alias `'full_name'`.\n    3. The model is populated by the field name `'name'`.\n    "
    use_enum_values: bool
    "\n    Whether to populate models with the `value` property of enums, rather than the raw enum.\n    This may be useful if you want to serialize `model.model_dump()` later. Defaults to `False`.\n\n    !!! note\n        If you have an `Optional[Enum]` value that you set a default for, you need to use `validate_default=True`\n        for said Field to ensure that the `use_enum_values` flag takes effect on the default, as extracting an\n        enum's value occurs during validation, not serialization.\n\n    ```py\n    from enum import Enum\n    from typing import Optional\n\n    from pydantic import BaseModel, ConfigDict, Field\n\n\n    class SomeEnum(Enum):\n        FOO = 'foo'\n        BAR = 'bar'\n        BAZ = 'baz'\n\n\n    class SomeModel(BaseModel):\n        model_config = ConfigDict(use_enum_values=True)\n\n        some_enum: SomeEnum\n        another_enum: Optional[SomeEnum] = Field(default=SomeEnum.FOO, validate_default=True)\n\n\n    model1 = SomeModel(some_enum=SomeEnum.BAR)\n    print(model1.model_dump())\n    # {'some_enum': 'bar', 'another_enum': 'foo'}\n\n    model2 = SomeModel(some_enum=SomeEnum.BAR, another_enum=SomeEnum.BAZ)\n    print(model2.model_dump())\n    #> {'some_enum': 'bar', 'another_enum': 'baz'}\n    ```\n    "
    validate_assignment: bool
    "\n    Whether to validate the data when the model is changed. Defaults to `False`.\n\n    The default behavior of Pydantic is to validate the data when the model is created.\n\n    In case the user changes the data after the model is created, the model is _not_ revalidated.\n\n    ```py\n    from pydantic import BaseModel\n\n    class User(BaseModel):\n        name: str\n\n    user = User(name='John Doe')  # (1)!\n    print(user)\n    #> name='John Doe'\n    user.name = 123  # (1)!\n    print(user)\n    #> name=123\n    ```\n\n    1. The validation happens only when the model is created.\n    2. The validation does not happen when the data is changed.\n\n    In case you want to revalidate the model when the data is changed, you can use `validate_assignment=True`:\n\n    ```py\n    from pydantic import BaseModel, ValidationError\n\n    class User(BaseModel, validate_assignment=True):  # (1)!\n        name: str\n\n    user = User(name='John Doe')  # (2)!\n    print(user)\n    #> name='John Doe'\n    try:\n        user.name = 123  # (3)!\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for User\n        name\n          Input should be a valid string [type=string_type, input_value=123, input_type=int]\n        '''\n    ```\n\n    1. You can either use class keyword arguments, or `model_config` to set `validate_assignment=True`.\n    2. The validation happens when the model is created.\n    3. The validation _also_ happens when the data is changed.\n    "
    arbitrary_types_allowed: bool
    "\n    Whether arbitrary types are allowed for field types. Defaults to `False`.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, ValidationError\n\n    # This is not a pydantic model, it's an arbitrary class\n    class Pet:\n        def __init__(self, name: str):\n            self.name = name\n\n    class Model(BaseModel):\n        model_config = ConfigDict(arbitrary_types_allowed=True)\n\n        pet: Pet\n        owner: str\n\n    pet = Pet(name='Hedwig')\n    # A simple check of instance type is used to validate the data\n    model = Model(owner='Harry', pet=pet)\n    print(model)\n    #> pet=<__main__.Pet object at 0x0123456789ab> owner='Harry'\n    print(model.pet)\n    #> <__main__.Pet object at 0x0123456789ab>\n    print(model.pet.name)\n    #> Hedwig\n    print(type(model.pet))\n    #> <class '__main__.Pet'>\n    try:\n        # If the value is not an instance of the type, it's invalid\n        Model(owner='Harry', pet='Hedwig')\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        pet\n          Input should be an instance of Pet [type=is_instance_of, input_value='Hedwig', input_type=str]\n        '''\n\n    # Nothing in the instance of the arbitrary type is checked\n    # Here name probably should have been a str, but it's not validated\n    pet2 = Pet(name=42)\n    model2 = Model(owner='Harry', pet=pet2)\n    print(model2)\n    #> pet=<__main__.Pet object at 0x0123456789ab> owner='Harry'\n    print(model2.pet)\n    #> <__main__.Pet object at 0x0123456789ab>\n    print(model2.pet.name)\n    #> 42\n    print(type(model2.pet))\n    #> <class '__main__.Pet'>\n    ```\n    "
    from_attributes: bool
    '\n    Whether to build models and look up discriminators of tagged unions using python object attributes.\n    '
    loc_by_alias: bool
    "Whether to use the actual key provided in the data (e.g. alias) for error `loc`s rather than the field's name. Defaults to `True`."
    alias_generator: Callable[[str], str] | AliasGenerator | None
    "\n    A callable that takes a field name and returns an alias for it\n    or an instance of [`AliasGenerator`][pydantic.aliases.AliasGenerator]. Defaults to `None`.\n\n    When using a callable, the alias generator is used for both validation and serialization.\n    If you want to use different alias generators for validation and serialization, you can use\n    [`AliasGenerator`][pydantic.aliases.AliasGenerator] instead.\n\n    If data source field names do not match your code style (e. g. CamelCase fields),\n    you can automatically generate aliases using `alias_generator`. Here's an example with\n    a basic callable:\n\n    ```py\n    from pydantic import BaseModel, ConfigDict\n    from pydantic.alias_generators import to_pascal\n\n    class Voice(BaseModel):\n        model_config = ConfigDict(alias_generator=to_pascal)\n\n        name: str\n        language_code: str\n\n    voice = Voice(Name='Filiz', LanguageCode='tr-TR')\n    print(voice.language_code)\n    #> tr-TR\n    print(voice.model_dump(by_alias=True))\n    #> {'Name': 'Filiz', 'LanguageCode': 'tr-TR'}\n    ```\n\n    If you want to use different alias generators for validation and serialization, you can use\n    [`AliasGenerator`][pydantic.aliases.AliasGenerator].\n\n    ```py\n    from pydantic import AliasGenerator, BaseModel, ConfigDict\n    from pydantic.alias_generators import to_camel, to_pascal\n\n    class Athlete(BaseModel):\n        first_name: str\n        last_name: str\n        sport: str\n\n        model_config = ConfigDict(\n            alias_generator=AliasGenerator(\n                validation_alias=to_camel,\n                serialization_alias=to_pascal,\n            )\n        )\n\n    athlete = Athlete(firstName='John', lastName='Doe', sport='track')\n    print(athlete.model_dump(by_alias=True))\n    #> {'FirstName': 'John', 'LastName': 'Doe', 'Sport': 'track'}\n    ```\n\n    Note:\n        Pydantic offers three built-in alias generators: [`to_pascal`][pydantic.alias_generators.to_pascal],\n        [`to_camel`][pydantic.alias_generators.to_camel], and [`to_snake`][pydantic.alias_generators.to_snake].\n    "
    ignored_types: tuple[type, ...]
    'A tuple of types that may occur as values of class attributes without annotations. This is\n    typically used for custom descriptors (classes that behave like `property`). If an attribute is set on a\n    class without an annotation and has a type that is not in this tuple (or otherwise recognized by\n    _pydantic_), an error will be raised. Defaults to `()`.\n    '
    allow_inf_nan: bool
    'Whether to allow infinity (`+inf` an `-inf`) and NaN values to float fields. Defaults to `True`.'
    json_schema_extra: JsonDict | JsonSchemaExtraCallable | None
    'A dict or callable to provide extra JSON schema properties. Defaults to `None`.'
    json_encoders: dict[type[object], JsonEncoder] | None
    '\n    A `dict` of custom JSON encoders for specific types. Defaults to `None`.\n\n    !!! warning "Deprecated"\n        This config option is a carryover from v1.\n        We originally planned to remove it in v2 but didn\'t have a 1:1 replacement so we are keeping it for now.\n        It is still deprecated and will likely be removed in the future.\n    '
    strict: bool
    "\n    _(new in V2)_ If `True`, strict validation is applied to all fields on the model.\n\n    By default, Pydantic attempts to coerce values to the correct type, when possible.\n\n    There are situations in which you may want to disable this behavior, and instead raise an error if a value's type\n    does not match the field's type annotation.\n\n    To configure strict mode for all fields on a model, you can set `strict=True` on the model.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict\n\n    class Model(BaseModel):\n        model_config = ConfigDict(strict=True)\n\n        name: str\n        age: int\n    ```\n\n    See [Strict Mode](../concepts/strict_mode.md) for more details.\n\n    See the [Conversion Table](../concepts/conversion_table.md) for more details on how Pydantic converts data in both\n    strict and lax modes.\n    "
    revalidate_instances: Literal['always', 'never', 'subclass-instances']
    "\n    When and how to revalidate models and dataclasses during validation. Accepts the string\n    values of `'never'`, `'always'` and `'subclass-instances'`. Defaults to `'never'`.\n\n    - `'never'` will not revalidate models and dataclasses during validation\n    - `'always'` will revalidate models and dataclasses during validation\n    - `'subclass-instances'` will revalidate models and dataclasses during validation if the instance is a\n        subclass of the model or dataclass\n\n    By default, model and dataclass instances are not revalidated during validation.\n\n    ```py\n    from typing import List\n\n    from pydantic import BaseModel\n\n    class User(BaseModel, revalidate_instances='never'):  # (1)!\n        hobbies: List[str]\n\n    class SubUser(User):\n        sins: List[str]\n\n    class Transaction(BaseModel):\n        user: User\n\n    my_user = User(hobbies=['reading'])\n    t = Transaction(user=my_user)\n    print(t)\n    #> user=User(hobbies=['reading'])\n\n    my_user.hobbies = [1]  # (2)!\n    t = Transaction(user=my_user)  # (3)!\n    print(t)\n    #> user=User(hobbies=[1])\n\n    my_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\n    t = Transaction(user=my_sub_user)\n    print(t)\n    #> user=SubUser(hobbies=['scuba diving'], sins=['lying'])\n    ```\n\n    1. `revalidate_instances` is set to `'never'` by **default.\n    2. The assignment is not validated, unless you set `validate_assignment` to `True` in the model's config.\n    3. Since `revalidate_instances` is set to `never`, this is not revalidated.\n\n    If you want to revalidate instances during validation, you can set `revalidate_instances` to `'always'`\n    in the model's config.\n\n    ```py\n    from typing import List\n\n    from pydantic import BaseModel, ValidationError\n\n    class User(BaseModel, revalidate_instances='always'):  # (1)!\n        hobbies: List[str]\n\n    class SubUser(User):\n        sins: List[str]\n\n    class Transaction(BaseModel):\n        user: User\n\n    my_user = User(hobbies=['reading'])\n    t = Transaction(user=my_user)\n    print(t)\n    #> user=User(hobbies=['reading'])\n\n    my_user.hobbies = [1]\n    try:\n        t = Transaction(user=my_user)  # (2)!\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Transaction\n        user.hobbies.0\n          Input should be a valid string [type=string_type, input_value=1, input_type=int]\n        '''\n\n    my_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\n    t = Transaction(user=my_sub_user)\n    print(t)  # (3)!\n    #> user=User(hobbies=['scuba diving'])\n    ```\n\n    1. `revalidate_instances` is set to `'always'`.\n    2. The model is revalidated, since `revalidate_instances` is set to `'always'`.\n    3. Using `'never'` we would have gotten `user=SubUser(hobbies=['scuba diving'], sins=['lying'])`.\n\n    It's also possible to set `revalidate_instances` to `'subclass-instances'` to only revalidate instances\n    of subclasses of the model.\n\n    ```py\n    from typing import List\n\n    from pydantic import BaseModel\n\n    class User(BaseModel, revalidate_instances='subclass-instances'):  # (1)!\n        hobbies: List[str]\n\n    class SubUser(User):\n        sins: List[str]\n\n    class Transaction(BaseModel):\n        user: User\n\n    my_user = User(hobbies=['reading'])\n    t = Transaction(user=my_user)\n    print(t)\n    #> user=User(hobbies=['reading'])\n\n    my_user.hobbies = [1]\n    t = Transaction(user=my_user)  # (2)!\n    print(t)\n    #> user=User(hobbies=[1])\n\n    my_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\n    t = Transaction(user=my_sub_user)\n    print(t)  # (3)!\n    #> user=User(hobbies=['scuba diving'])\n    ```\n\n    1. `revalidate_instances` is set to `'subclass-instances'`.\n    2. This is not revalidated, since `my_user` is not a subclass of `User`.\n    3. Using `'never'` we would have gotten `user=SubUser(hobbies=['scuba diving'], sins=['lying'])`.\n    "
    ser_json_timedelta: Literal['iso8601', 'float']
    "\n    The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n    `'float'`. Defaults to `'iso8601'`.\n\n    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n    - `'float'` will serialize timedeltas to the total number of seconds.\n    "
    ser_json_bytes: Literal['utf8', 'base64']
    "\n    The encoding of JSON serialized bytes. Accepts the string values of `'utf8'` and `'base64'`.\n    Defaults to `'utf8'`.\n\n    - `'utf8'` will serialize bytes to UTF-8 strings.\n    - `'base64'` will serialize bytes to URL safe base64 strings.\n    "
    ser_json_inf_nan: Literal['null', 'constants', 'strings']
    '\n    The encoding of JSON serialized infinity and NaN float values. Defaults to `\'null\'`.\n\n    - `\'null\'` will serialize infinity and NaN values as `null`.\n    - `\'constants\'` will serialize infinity and NaN values as `Infinity` and `NaN`.\n    - `\'strings\'` will serialize infinity as string `"Infinity"` and NaN as string `"NaN"`.\n    '
    validate_default: bool
    'Whether to validate default values during validation. Defaults to `False`.'
    validate_return: bool
    'whether to validate the return value from call validators. Defaults to `False`.'
    protected_namespaces: tuple[str, ...]
    '\n    A `tuple` of strings that prevent model to have field which conflict with them.\n    Defaults to `(\'model_\', )`).\n\n    Pydantic prevents collisions between model attributes and `BaseModel`\'s own methods by\n    namespacing them with the prefix `model_`.\n\n    ```py\n    import warnings\n\n    from pydantic import BaseModel\n\n    warnings.filterwarnings(\'error\')  # Raise warnings as errors\n\n    try:\n\n        class Model(BaseModel):\n            model_prefixed_field: str\n\n    except UserWarning as e:\n        print(e)\n        \'\'\'\n        Field "model_prefixed_field" has conflict with protected namespace "model_".\n\n        You may be able to resolve this warning by setting `model_config[\'protected_namespaces\'] = ()`.\n        \'\'\'\n    ```\n\n    You can customize this behavior using the `protected_namespaces` setting:\n\n    ```py\n    import warnings\n\n    from pydantic import BaseModel, ConfigDict\n\n    warnings.filterwarnings(\'error\')  # Raise warnings as errors\n\n    try:\n\n        class Model(BaseModel):\n            model_prefixed_field: str\n            also_protect_field: str\n\n            model_config = ConfigDict(\n                protected_namespaces=(\'protect_me_\', \'also_protect_\')\n            )\n\n    except UserWarning as e:\n        print(e)\n        \'\'\'\n        Field "also_protect_field" has conflict with protected namespace "also_protect_".\n\n        You may be able to resolve this warning by setting `model_config[\'protected_namespaces\'] = (\'protect_me_\',)`.\n        \'\'\'\n    ```\n\n    While Pydantic will only emit a warning when an item is in a protected namespace but does not actually have a collision,\n    an error _is_ raised if there is an actual collision with an existing attribute:\n\n    ```py\n    from pydantic import BaseModel\n\n    try:\n\n        class Model(BaseModel):\n            model_validate: str\n\n    except NameError as e:\n        print(e)\n        \'\'\'\n        Field "model_validate" conflicts with member <bound method BaseModel.model_validate of <class \'pydantic.main.BaseModel\'>> of protected namespace "model_".\n        \'\'\'\n    ```\n    '
    hide_input_in_errors: bool
    "\n    Whether to hide inputs when printing errors. Defaults to `False`.\n\n    Pydantic shows the input value and type when it raises `ValidationError` during the validation.\n\n    ```py\n    from pydantic import BaseModel, ValidationError\n\n    class Model(BaseModel):\n        a: str\n\n    try:\n        Model(a=123)\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        a\n          Input should be a valid string [type=string_type, input_value=123, input_type=int]\n        '''\n    ```\n\n    You can hide the input value and type by setting the `hide_input_in_errors` config to `True`.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, ValidationError\n\n    class Model(BaseModel):\n        a: str\n        model_config = ConfigDict(hide_input_in_errors=True)\n\n    try:\n        Model(a=123)\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        a\n          Input should be a valid string [type=string_type]\n        '''\n    ```\n    "
    defer_build: bool
    "\n    Whether to defer model validator and serializer construction until the first model validation. Defaults to False.\n\n    This can be useful to avoid the overhead of building models which are only\n    used nested within other models, or when you want to manually define type namespace via\n    [`Model.model_rebuild(_types_namespace=...)`][pydantic.BaseModel.model_rebuild].\n\n    See also [`experimental_defer_build_mode`][pydantic.config.ConfigDict.experimental_defer_build_mode].\n\n    !!! note\n        `defer_build` does not work by default with FastAPI Pydantic models. By default, the validator and serializer\n        for said models is constructed immediately for FastAPI routes. You also need to define\n        [`experimental_defer_build_mode=('model', 'type_adapter')`][pydantic.config.ConfigDict.experimental_defer_build_mode] with FastAPI\n        models in order for `defer_build=True` to take effect. This additional (experimental) parameter is required for\n        the deferred building due to FastAPI relying on `TypeAdapter`s.\n    "
    experimental_defer_build_mode: tuple[Literal['model', 'type_adapter'], ...]
    "\n    Controls when [`defer_build`][pydantic.config.ConfigDict.defer_build] is applicable. Defaults to `('model',)`.\n\n    Due to backwards compatibility reasons [`TypeAdapter`][pydantic.type_adapter.TypeAdapter] does not by default\n    respect `defer_build`. Meaning when `defer_build` is `True` and `experimental_defer_build_mode` is the default `('model',)`\n    then `TypeAdapter` immediately constructs its validator and serializer instead of postponing said construction until\n    the first model validation. Set this to `('model', 'type_adapter')` to make `TypeAdapter` respect the `defer_build`\n    so it postpones validator and serializer construction until the first validation or serialization.\n\n    !!! note\n        The `experimental_defer_build_mode` parameter is named with an underscore to suggest this is an experimental feature. It may\n        be removed or changed in the future in a minor release.\n    "
    plugin_settings: dict[str, object] | None
    'A `dict` of settings for plugins. Defaults to `None`.\n\n    See [Pydantic Plugins](../concepts/plugins.md) for details.\n    '
    schema_generator: type[_GenerateSchema] | None
    '\n    A custom core schema generator class to use when generating JSON schemas.\n    Useful if you want to change the way types are validated across an entire model/schema. Defaults to `None`.\n\n    The `GenerateSchema` interface is subject to change, currently only the `string_schema` method is public.\n\n    See [#6737](https://github.com/pydantic/pydantic/pull/6737) for details.\n    '
    json_schema_serialization_defaults_required: bool
    "\n    Whether fields with default values should be marked as required in the serialization schema. Defaults to `False`.\n\n    This ensures that the serialization schema will reflect the fact a field with a default will always be present\n    when serializing the model, even though it is not required for validation.\n\n    However, there are scenarios where this may be undesirable — in particular, if you want to share the schema\n    between validation and serialization, and don't mind fields with defaults being marked as not required during\n    serialization. See [#7209](https://github.com/pydantic/pydantic/issues/7209) for more details.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict\n\n    class Model(BaseModel):\n        a: str = 'a'\n\n        model_config = ConfigDict(json_schema_serialization_defaults_required=True)\n\n    print(Model.model_json_schema(mode='validation'))\n    '''\n    {\n        'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},\n        'title': 'Model',\n        'type': 'object',\n    }\n    '''\n    print(Model.model_json_schema(mode='serialization'))\n    '''\n    {\n        'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},\n        'required': ['a'],\n        'title': 'Model',\n        'type': 'object',\n    }\n    '''\n    ```\n    "
    json_schema_mode_override: Literal['validation', 'serialization', None]
    "\n    If not `None`, the specified mode will be used to generate the JSON schema regardless of what `mode` was passed to\n    the function call. Defaults to `None`.\n\n    This provides a way to force the JSON schema generation to reflect a specific mode, e.g., to always use the\n    validation schema.\n\n    It can be useful when using frameworks (such as FastAPI) that may generate different schemas for validation\n    and serialization that must both be referenced from the same schema; when this happens, we automatically append\n    `-Input` to the definition reference for the validation schema and `-Output` to the definition reference for the\n    serialization schema. By specifying a `json_schema_mode_override` though, this prevents the conflict between\n    the validation and serialization schemas (since both will use the specified schema), and so prevents the suffixes\n    from being added to the definition references.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, Json\n\n    class Model(BaseModel):\n        a: Json[int]  # requires a string to validate, but will dump an int\n\n    print(Model.model_json_schema(mode='serialization'))\n    '''\n    {\n        'properties': {'a': {'title': 'A', 'type': 'integer'}},\n        'required': ['a'],\n        'title': 'Model',\n        'type': 'object',\n    }\n    '''\n\n    class ForceInputModel(Model):\n        # the following ensures that even with mode='serialization', we\n        # will get the schema that would be generated for validation.\n        model_config = ConfigDict(json_schema_mode_override='validation')\n\n    print(ForceInputModel.model_json_schema(mode='serialization'))\n    '''\n    {\n        'properties': {\n            'a': {\n                'contentMediaType': 'application/json',\n                'contentSchema': {'type': 'integer'},\n                'title': 'A',\n                'type': 'string',\n            }\n        },\n        'required': ['a'],\n        'title': 'ForceInputModel',\n        'type': 'object',\n    }\n    '''\n    ```\n    "
    coerce_numbers_to_str: bool
    '\n    If `True`, enables automatic coercion of any `Number` type to `str` in "lax" (non-strict) mode. Defaults to `False`.\n\n    Pydantic doesn\'t allow number types (`int`, `float`, `Decimal`) to be coerced as type `str` by default.\n\n    ```py\n    from decimal import Decimal\n\n    from pydantic import BaseModel, ConfigDict, ValidationError\n\n    class Model(BaseModel):\n        value: str\n\n    try:\n        print(Model(value=42))\n    except ValidationError as e:\n        print(e)\n        \'\'\'\n        1 validation error for Model\n        value\n          Input should be a valid string [type=string_type, input_value=42, input_type=int]\n        \'\'\'\n\n    class Model(BaseModel):\n        model_config = ConfigDict(coerce_numbers_to_str=True)\n\n        value: str\n\n    repr(Model(value=42).value)\n    #> "42"\n    repr(Model(value=42.13).value)\n    #> "42.13"\n    repr(Model(value=Decimal(\'42.13\')).value)\n    #> "42.13"\n    ```\n    '
    regex_engine: Literal['rust-regex', 'python-re']
    "\n    The regex engine to be used for pattern validation.\n    Defaults to `'rust-regex'`.\n\n    - `rust-regex` uses the [`regex`](https://docs.rs/regex) Rust crate,\n      which is non-backtracking and therefore more DDoS resistant, but does not support all regex features.\n    - `python-re` use the [`re`](https://docs.python.org/3/library/re.html) module,\n      which supports all regex features, but may be slower.\n\n    !!! note\n        If you use a compiled regex pattern, the python-re engine will be used regardless of this setting.\n        This is so that flags such as `re.IGNORECASE` are respected.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, Field, ValidationError\n\n    class Model(BaseModel):\n        model_config = ConfigDict(regex_engine='python-re')\n\n        value: str = Field(pattern=r'^abc(?=def)')\n\n    print(Model(value='abcdef').value)\n    #> abcdef\n\n    try:\n        print(Model(value='abxyzcdef'))\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        value\n          String should match pattern '^abc(?=def)' [type=string_pattern_mismatch, input_value='abxyzcdef', input_type=str]\n        '''\n    ```\n    "
    validation_error_cause: bool
    "\n    If `True`, Python exceptions that were part of a validation failure will be shown as an exception group as a cause. Can be useful for debugging. Defaults to `False`.\n\n    Note:\n        Python 3.10 and older don't support exception groups natively. <=3.10, backport must be installed: `pip install exceptiongroup`.\n\n    Note:\n        The structure of validation errors are likely to change in future Pydantic versions. Pydantic offers no guarantees about their structure. Should be used for visual traceback debugging only.\n    "
    use_attribute_docstrings: bool
    '\n    Whether docstrings of attributes (bare string literals immediately following the attribute declaration)\n    should be used for field descriptions. Defaults to `False`.\n\n    Available in Pydantic v2.7+.\n\n    ```py\n    from pydantic import BaseModel, ConfigDict, Field\n\n\n    class Model(BaseModel):\n        model_config = ConfigDict(use_attribute_docstrings=True)\n\n        x: str\n        """\n        Example of an attribute docstring\n        """\n\n        y: int = Field(description="Description in Field")\n        """\n        Description in Field overrides attribute docstring\n        """\n\n\n    print(Model.model_fields["x"].description)\n    # > Example of an attribute docstring\n    print(Model.model_fields["y"].description)\n    # > Description in Field\n    ```\n    This requires the source code of the class to be available at runtime.\n\n    !!! warning "Usage with `TypedDict`"\n        Due to current limitations, attribute docstrings detection may not work as expected when using `TypedDict`\n        (in particular when multiple `TypedDict` classes have the same name in the same source file). The behavior\n        can be different depending on the Python version used.\n    '
    cache_strings: bool | Literal['all', 'keys', 'none']
    "\n    Whether to cache strings to avoid constructing new Python objects. Defaults to True.\n\n    Enabling this setting should significantly improve validation performance while increasing memory usage slightly.\n\n    - `True` or `'all'` (the default): cache all strings\n    - `'keys'`: cache only dictionary keys\n    - `False` or `'none'`: no caching\n\n    !!! note\n        `True` or `'all'` is required to cache strings during general validation because\n        validators don't know if they're in a key or a value.\n\n    !!! tip\n        If repeated strings are rare, it's recommended to use `'keys'` or `'none'` to reduce memory usage,\n        as the performance difference is minimal if repeated strings are rare.\n    "
_TypeT = TypeVar('_TypeT', bound=type)

def with_config(config: ConfigDict) -> Callable[[_TypeT], _TypeT]:
    """Usage docs: https://docs.pydantic.dev/2.8/concepts/config/#configuration-with-dataclass-from-the-standard-library-or-typeddict

    A convenience decorator to set a [Pydantic configuration](config.md) on a `TypedDict` or a `dataclass` from the standard library.

    Although the configuration can be set using the `__pydantic_config__` attribute, it does not play well with type checkers,
    especially with `TypedDict`.

    !!! example "Usage"

        ```py
        from typing_extensions import TypedDict

        from pydantic import ConfigDict, TypeAdapter, with_config

        @with_config(ConfigDict(str_to_lower=True))
        class Model(TypedDict):
            x: str

        ta = TypeAdapter(Model)

        print(ta.validate_python({'x': 'ABC'}))
        #> {'x': 'abc'}
        ```
    """
    def decorator(cls: _TypeT) -> _TypeT:
        setattr(cls, '__pydantic_config__', config)
        return cls
    return decorator
__getattr__ = getattr_migration(__name__)
